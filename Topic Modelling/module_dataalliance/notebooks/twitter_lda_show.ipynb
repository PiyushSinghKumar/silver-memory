{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ae2fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilgoncalo/miniconda3/envs/dataalliance/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "from gensim.models import CoherenceModel\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from data_storage import retrieve_twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef8edf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = retrieve_twitter_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac585cf",
   "metadata": {},
   "source": [
    "#### Create corpus, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23cdb4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Corpus\n",
    "texts = df['lemmatized_text'].values\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(texts)\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7b808",
   "metadata": {},
   "source": [
    "# LDA\n",
    "Hyperparameters:\n",
    "- Alpha - higher means documents are assumed to be made up of more topics - try 0.1\n",
    "- Beta - controls distribution of words per topic, higher means topics have more words\n",
    "\n",
    "*default = 1.0 for both*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb5ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=6, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=2,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e91a66",
   "metadata": {},
   "source": [
    "#### Coherence scores\n",
    "The overall coherence score of a topic is the average of the distances between words.\n",
    "For u_mass the closer to 0 the better. It is a logarithmic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b85f2158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  -3.7709936395099586\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score - 'c_v' is the best coherence score, but slow\n",
    "#                         - 'u_mass' requires corpus\n",
    "coherence_model_lda = CoherenceModel(model=lda_model,\n",
    "                                     corpus=corpus,\n",
    "                                     texts=texts,\n",
    "                                     dictionary=id2word,\n",
    "                                     coherence='u_mass') \n",
    "\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ddca1e",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c87661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilgoncalo/miniconda3/envs/dataalliance/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/home/devilgoncalo/miniconda3/envs/dataalliance/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/devilgoncalo/miniconda3/envs/dataalliance/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/devilgoncalo/miniconda3/envs/dataalliance/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/devilgoncalo/miniconda3/envs/dataalliance/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el153081405335534914084496485383\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el153081405335534914084496485383_data = {\"mdsDat\": {\"x\": [-0.20559550841443028, -0.04757715133929966, 0.08004266838171466, -0.20439629497723208, 0.18548586043390733, 0.19204042591533962], \"y\": [0.0065461665608097085, 0.0689337680490477, 0.15806105451038818, -0.08828787265366923, -0.2780752563929776, 0.13282213992640124], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [20.93310644345942, 20.210590698501747, 17.375922605406068, 15.341728895111642, 13.3649184674881, 12.773732890033024]}, \"tinfo\": {\"Term\": [\"vaccine\", \"case\", \"test\", \"new\", \"get\", \"death\", \"day\", \"booster\", \"m\", \"report\", \"mask\", \"want\", \"bad\", \"people\", \"go\", \"symptom\", \"update\", \"health\", \"infection\", \"positive\", \"public\", \"shot\", \"trump\", \"feel\", \"end\", \"high\", \"well\", \"fall\", \"lockdown\", \"negative\", \"negative\", \"tomorrow\", \"head\", \"mom\", \"dead\", \"visit\", \"wish\", \"line\", \"tired\", \"date\", \"seriously\", \"wake\", \"trip\", \"suppose\", \"guidance\", \"war\", \"online\", \"australian\", \"stream\", \"cry\", \"double\", \"pain\", \"bitch\", \"rapid\", \"small\", \"air\", \"we_re\", \"destroy\", \"test\", \"movie\", \"tonight\", \"want\", \"probably\", \"friend\", \"finally\", \"m\", \"positive\", \"home\", \"soon\", \"go\", \"hope\", \"come\", \"right\", \"time\", \"think\", \"sick\", \"take\", \"thing\", \"feel\", \"get\", \"covid\", \"family\", \"catch\", \"work\", \"start\", \"stop\", \"people\", \"watch\", \"year\", \"good\", \"know\", \"tell\", \"today\", \"need\", \"week\", \"play\", \"real\", \"check\", \"lead\", \"game\", \"control\", \"hand\", \"safety\", \"damn\", \"ill\", \"admit\", \"listen\", \"refuse\", \"tweet\", \"write\", \"later\", \"word\", \"market\", \"federal\", \"sorry\", \"chance\", \"deadly\", \"answer\", \"power\", \"hot\", \"immunity\", \"joke\", \"trust\", \"you_re\", \"cure\", \"future\", \"understand\", \"sure\", \"job\", \"force\", \"well\", \"guess\", \"protection\", \"employee\", \"science\", \"people\", \"amp\", \"care\", \"question\", \"expert\", \"issue\", \"covid\", \"kill\", \"long\", \"effect\", \"know\", \"way\", \"pandemic\", \"need\", \"virus\", \"protect\", \"vaccine\", \"say\", \"great\", \"lose\", \"government\", \"die\", \"lot\", \"world\", \"health\", \"get\", \"mask\", \"work\", \"year\", \"think\", \"go\", \"update\", \"flu\", \"symptom\", \"increase\", \"age\", \"suck\", \"report\", \"bit\", \"scientist\", \"fire\", \"instead\", \"total\", \"shoot\", \"twice\", \"nearly\", \"win\", \"true\", \"suggest\", \"strain\", \"condition\", \"protocol\", \"lung\", \"campaign\", \"individual\", \"completely\", \"exactly\", \"loss\", \"survive\", \"researcher\", \"active\", \"case\", \"death\", \"mild\", \"severe\", \"number\", \"infection\", \"new\", \"research\", \"recently\", \"patient\", \"study\", \"high\", \"risk\", \"rate\", \"rise\", \"daily\", \"vaccination\", \"vaccinate\", \"outbreak\", \"covid\", \"month\", \"level\", \"datum\", \"low\", \"day\", \"die\", \"week\", \"year\", \"show\", \"people\", \"child\", \"today\", \"long\", \"say\", \"remember\", \"man\", \"keep\", \"money\", \"season\", \"wonder\", \"night\", \"maybe\", \"confirm\", \"reduce\", \"corona\", \"morning\", \"girl\", \"fever\", \"challenge\", \"bill\", \"bed\", \"source\", \"concert\", \"house\", \"feeling\", \"weekly\", \"manage\", \"battle\", \"vacation\", \"choose\", \"fake\", \"birthday\", \"dog\", \"fatigue\", \"eat\", \"teacher\", \"crazy\", \"body\", \"send\", \"class\", \"day\", \"bad\", \"taste\", \"pretty\", \"get\", \"kid\", \"ve\", \"leave\", \"covid\", \"fuck\", \"shit\", \"feel\", \"help\", \"good\", \"little\", \"week\", \"school\", \"know\", \"time\", \"look\", \"go\", \"work\", \"today\", \"thing\", \"lose\", \"need\", \"fact\", \"cough\", \"coronavirus\", \"book\", \"inflation\", \"blame\", \"drug\", \"guideline\", \"border\", \"common\", \"focus\", \"economic\", \"decision\", \"price\", \"drink\", \"period\", \"misinformation\", \"situation\", \"water\", \"interview\", \"statement\", \"recommendation\", \"publish\", \"block\", \"origin\", \"worldwide\", \"remove\", \"excuse\", \"episode\", \"previous\", \"booster\", \"trump\", \"crisis\", \"team\", \"release\", \"adult\", \"recommend\", \"student\", \"emergency\", \"walk\", \"major\", \"recent\", \"public\", \"add\", \"shot\", \"mask\", \"end\", \"wear\", \"staff\", \"health\", \"official\", \"school\", \"news\", \"policy\", \"covid\", \"tested_positive\", \"pandemic\", \"state\", \"amp\", \"say\", \"continue\", \"biden\", \"year\", \"fall\", \"lockdown\", \"turn\", \"summer\", \"twitter\", \"sit\", \"couple\", \"relate\", \"evidence\", \"shut\", \"reveal\", \"short\", \"mention\", \"idea\", \"handle\", \"interesting\", \"benefit\", \"chinese\", \"fraud\", \"extend\", \"accept\", \"d\", \"raise\", \"meeting\", \"car\", \"requirement\", \"message\", \"fauci\", \"approve\", \"tv\", \"entire\", \"bring\", \"boost\", \"stuff\", \"happy\", \"rule\", \"enter\", \"ass\", \"thread\", \"vaccine\", \"surge\", \"declare\", \"mandate\", \"medium\", \"travel\", \"drop\", \"variant\", \"story\", \"country\", \"covid\", \"happen\", \"say\", \"child\", \"restriction\", \"fight\", \"thank\", \"ago\", \"new\", \"pandemic\", \"year\", \"government\", \"cause\", \"call\"], \"Freq\": [14573.0, 8755.0, 9409.0, 10398.0, 16870.0, 7289.0, 9442.0, 5509.0, 6349.0, 3903.0, 4735.0, 4497.0, 4888.0, 13737.0, 9287.0, 3341.0, 3207.0, 5603.0, 3358.0, 4041.0, 2774.0, 3032.0, 2330.0, 5419.0, 2948.0, 3230.0, 2903.0, 1929.0, 1914.0, 2417.0, 2416.4116684051573, 1080.4427542605297, 963.8859486565585, 906.3564358866888, 872.3898829848088, 869.5328083057859, 723.1840135279373, 706.6858332668131, 653.7564490002344, 647.7891557497284, 612.0231584417172, 583.8236436318324, 543.7842366206966, 544.7170639220773, 541.3472392851803, 517.4473077839583, 515.3075343027812, 512.8872158717596, 517.8850026716065, 490.13076406959465, 479.03593513882214, 478.0806887904908, 475.11772833899414, 457.5645893178194, 453.40782364158275, 439.8809071826777, 434.43535316974106, 426.21005394407507, 9390.084600646293, 421.17064208604125, 765.2266941546781, 4405.363087059637, 1049.4818699140797, 1821.5098025439975, 2250.6278343171766, 5646.888462635192, 3643.6110924716327, 2434.01361668797, 1191.8128537849557, 6105.012769994754, 1313.399035023044, 3735.87359351659, 2105.6568181348575, 5649.54495724198, 3577.745159982516, 2364.754429672309, 2638.5804525182048, 2541.275290477974, 3145.4727213714, 6738.902405447288, 24420.434622579345, 1437.7569469353382, 1937.9487727707594, 3022.1458690096856, 2011.8239007576094, 1702.0087009768927, 4003.3263975662267, 1265.8965041795138, 2808.1885933398003, 1981.3313975949557, 2280.022129092973, 1697.6227989222411, 1844.6022151366979, 1761.7811292845224, 1802.3901461552189, 1664.964382937348, 1508.587712823084, 1215.7472993114386, 997.3992171404809, 1170.6683091520383, 832.9088223508982, 812.4267756140024, 804.1245525881064, 763.4120458551558, 748.9705904918688, 769.9764451452731, 739.0970134273758, 711.0587203101201, 661.4675508837717, 657.281200496483, 658.118777302026, 654.9909176525955, 623.8927330411656, 619.7139114341516, 613.192523786899, 555.9431906027704, 541.985773071301, 537.0205076247752, 534.2143290547602, 522.6000003954929, 503.9413824145345, 500.7330414981877, 501.05329350356965, 702.9656997805565, 490.61840404305224, 734.5259284258724, 776.9039686617803, 1393.3541538469171, 1644.376375589181, 851.0528342579058, 2774.201888282962, 1056.987700529353, 630.8261819865925, 580.6190467963008, 976.0128802394983, 7066.599607237895, 4862.875429010495, 1866.1338101387232, 943.8193278090507, 1077.8859912201312, 1062.4010329686068, 17108.95909867541, 1296.8569405369506, 2418.2470126205335, 1121.7827537436428, 2679.5603798888137, 1497.4063587405312, 2399.9891627673373, 2080.6335005036053, 1602.4533385833836, 1111.4281015617921, 3188.0254787289573, 2335.254897482672, 1201.093643881895, 1253.7014143158392, 1371.5085613491874, 1645.8244109953182, 1148.2681662183456, 1276.2501112380971, 1480.730389276131, 1862.609783282809, 1366.9193515062823, 1391.9144837521962, 1310.4990903944235, 1242.287783419631, 1240.5557456909153, 3206.5364350155196, 1494.0743914672155, 3339.2790972002913, 1782.8749311478052, 1102.4020524180362, 1079.1245952201002, 3899.725766772749, 830.2494244088738, 815.5570833289978, 795.6810927206878, 791.2621348830074, 770.9719437672281, 770.2412343782737, 732.7278897345068, 646.4464658649858, 643.2606400546789, 628.96409989382, 539.8360738968565, 521.8379800474137, 605.9881681991509, 491.98554678644024, 489.052730300729, 485.182254006111, 473.01422258820014, 459.68440998999176, 455.7240334260634, 452.0533155298529, 447.39351487069007, 434.6861717371865, 441.26417444262404, 8736.253094547988, 7272.025113023702, 866.4110885368033, 734.7700642521605, 2254.121954175416, 3111.0728973062046, 8997.270735133885, 1115.5351632269935, 580.8362304525814, 2094.7028854106225, 2097.129713213899, 2602.0968888555085, 2479.277058796135, 1380.5552836696124, 1318.5941001885146, 1092.14179461516, 2186.299033401232, 1717.2047022890144, 1112.6927564454522, 25952.204532160682, 2391.1927749258643, 1170.7568231854596, 1162.795734803439, 1063.592945225943, 2730.4051902897913, 1984.6866517064275, 2303.1475677059875, 2432.744679401103, 1255.8537810400605, 2024.6070460942224, 1392.9234031202516, 1395.089879743605, 1270.6397382670448, 1269.0075089774464, 1582.6591711608478, 1575.185157744799, 1124.0210263414567, 1712.3472740478303, 990.562578963583, 962.4766081577093, 1003.4508599856674, 1141.8367375054897, 790.028247872073, 689.0716516849204, 668.5155747692344, 660.7297207905915, 639.6743179715222, 609.3500060902771, 600.5923292825084, 585.8761323341242, 568.5825543503247, 572.9643561126861, 554.979945183924, 549.5800181162327, 540.1399751020073, 498.57141114805347, 476.6074214530739, 465.63278208466113, 463.3999443893186, 458.2037482169247, 451.4081851407736, 445.35970590353344, 436.9646965479517, 438.56618013633533, 861.836032985288, 614.5890122092413, 550.2488375410801, 951.0700063741506, 1286.7542804456584, 779.4941434915434, 6697.051726961541, 3705.1882813824814, 655.119501105261, 780.8403549139753, 8182.369546360123, 1682.014865847889, 1622.9746048988186, 1423.7755313867985, 17716.99237974994, 1317.5498192418702, 1087.0869962942643, 1916.0241938871375, 1363.1853281199988, 1647.1749777358898, 954.9042747407611, 1858.60616003579, 1414.7885117997523, 1803.3937115652193, 1999.745632586181, 1195.3100120527251, 1801.118910597157, 1343.8517424103277, 1218.8679711056643, 1115.1832330205764, 1018.3616331683393, 1061.5064392465063, 1234.1300979788161, 1212.3607497685352, 1214.3450199065671, 990.5974025647531, 832.9563506076847, 757.2494194080499, 736.9468840293375, 650.9054199713626, 639.7229025114729, 568.1950902049106, 565.0807117490215, 562.3794232640203, 517.5809891317682, 499.30564173093774, 471.4246271708755, 460.800733108734, 453.36668098672936, 444.5049998826434, 433.13043546162004, 406.4839887522834, 387.2184885242346, 366.2135941681257, 364.1857608091934, 360.6487038639535, 359.18396547147546, 346.893858882522, 351.04990540304357, 331.0053841485428, 324.6813643838641, 316.82525610423585, 5493.437770955355, 2321.7612790461585, 1096.055155523333, 854.1833943410627, 789.0852829461785, 707.6322476631548, 635.0355460412281, 1422.192568704818, 1022.6751457008339, 697.8274804498815, 698.0237223878427, 547.22260319726, 2517.3434531792795, 673.7518630560769, 2555.8487305906547, 3329.4706835697903, 2213.4611757444236, 1156.640025035635, 804.8698282817237, 3123.936364850678, 908.4688838152165, 1925.6619784795587, 1449.2411339071864, 1072.3305793222871, 9105.5145470695, 905.1104130263453, 1899.5476484462583, 1096.4285545596229, 1812.7215854256103, 1522.1173777212193, 948.4202757659019, 906.1125976002885, 985.4588786416481, 1928.1681758898017, 1913.6997368353964, 1103.7465752189373, 1000.7785244740643, 847.0632555894665, 709.7099273817713, 637.3650885389764, 610.2639940908826, 614.5849105121015, 579.5252140867055, 605.3788074891137, 535.446887865326, 505.51219396992065, 733.5252836621033, 549.5422309652612, 463.40733738678733, 447.38950150492633, 427.8200723550116, 423.90666236776696, 420.99736867744883, 414.493699932139, 414.6292269935407, 399.5439107002909, 387.09141465448016, 374.0583464083798, 549.2135029401901, 362.9096374358687, 350.80071747094576, 341.06955723380827, 324.67477019010636, 635.9969084877057, 1267.1897439367247, 668.4399985663763, 560.472867379122, 867.9126576460075, 1190.7566229003444, 445.7605772568496, 773.9668495771685, 469.70304523163674, 11200.560498279863, 764.0727572616619, 532.0894208107105, 1348.191307737287, 747.5366933901366, 899.3816359559748, 997.1140947937056, 1156.5108378550767, 981.8457993437582, 1323.0405516832145, 12969.377929239667, 1197.0126331241524, 2100.0801116837115, 1315.8493342405138, 827.5392517972583, 797.9733800835805, 981.034223117809, 815.8881542299379, 1338.110931801622, 1120.5069020106623, 1161.9368549765811, 899.3181902575293, 822.6714687030491, 764.8183323374227], \"Total\": [14573.0, 8755.0, 9409.0, 10398.0, 16870.0, 7289.0, 9442.0, 5509.0, 6349.0, 3903.0, 4735.0, 4497.0, 4888.0, 13737.0, 9287.0, 3341.0, 3207.0, 5603.0, 3358.0, 4041.0, 2774.0, 3032.0, 2330.0, 5419.0, 2948.0, 3230.0, 2903.0, 1929.0, 1914.0, 2417.0, 2417.296755280908, 1081.310942816844, 964.7457943551276, 907.2112267447161, 873.2485556028824, 870.3902892982203, 724.0773718037161, 707.5742285358318, 654.6227083962099, 648.6504494930009, 612.8804499082754, 584.6814833662193, 544.6386083866904, 545.588323955541, 542.2174845619298, 518.305653952498, 516.1663512889703, 513.7466664046138, 518.7806709868528, 490.98609025892296, 479.89468082510336, 478.93961974434507, 475.97238998897905, 458.42051609035457, 454.27003910518505, 440.73976230570906, 435.2918195176785, 427.0702708637646, 9409.085218251323, 422.0260200173899, 766.7908279165518, 4497.694944696899, 1056.7882670214603, 1852.3556998664187, 2398.064140514097, 6349.427319826492, 4041.9592411577737, 2858.9603889522473, 1306.2020285087458, 9287.169781874129, 1548.0970151023594, 5337.548249965692, 2748.488025865117, 9710.08838552199, 5598.315961560911, 3361.255329650324, 4184.817863572388, 4038.7270855830448, 5419.426037629178, 16870.994069531782, 107273.48310947453, 1996.0189079843592, 3106.294967871076, 6471.135036164916, 3437.451743232985, 2848.800072845993, 13737.999181365556, 1700.2165820590553, 9287.008981143206, 4682.102530622856, 7056.837933399104, 3488.4917502632575, 5015.560075806641, 5190.446828714766, 6940.98592504554, 1665.8281634814473, 1509.4408980688263, 1216.6016546217909, 998.2519730842534, 1171.7069676622075, 833.7621545844394, 813.2814112405542, 804.9798724341904, 764.2652950809389, 749.8245176763161, 770.8544689274165, 739.950125666786, 711.9114561577586, 662.3212561910361, 658.1352451394094, 658.9740734050586, 655.8454915065804, 624.7485581805029, 620.5683762752103, 614.0473473092136, 556.7968488378432, 542.8412933990205, 537.8733670356588, 535.068801194253, 523.4560780896522, 504.7935758900165, 501.58600714153357, 501.9078152828224, 704.1760543517642, 491.472456222563, 736.9013684804971, 780.0757730633528, 1415.3482065697817, 1683.01944048131, 860.3123778363353, 2903.434401591828, 1079.8440095158323, 639.6931511983527, 585.7765335226248, 1110.596770412217, 13737.999181365556, 9543.787681173608, 2667.1662010634295, 1095.8233413547894, 1321.3659266571935, 1378.7442941577278, 107273.48310947453, 1904.099944534823, 5344.23624417894, 1538.782568565739, 7056.837933399104, 2617.6281536775728, 6452.213308161425, 5190.446828714766, 3146.8019413800457, 1569.4244392978133, 14573.547903922637, 8718.828658095616, 2046.4455246969562, 2281.396698882755, 2874.9705962751905, 5042.9559296965435, 1865.5425135935639, 2847.3141015354245, 5603.986739880363, 16870.994069531782, 4735.048809182113, 6471.135036164916, 9287.008981143206, 5598.315961560911, 9287.169781874129, 3207.390221495216, 1494.9770219079228, 3341.6103948437662, 1784.2261806129927, 1103.2449189110293, 1079.9697082728032, 3903.6809491044783, 831.0969081299916, 816.4049373746925, 796.5310472912656, 792.1120254760688, 771.8125171664665, 771.086555722563, 733.5733109135286, 647.288847962175, 644.1072197625109, 629.8107479228365, 540.681234697577, 522.6819560821094, 607.0173545943894, 492.8309748092872, 489.90041693334354, 486.02815922944524, 473.8616246039724, 460.53240311576513, 456.5719090018838, 452.8987763770961, 448.2380393145683, 435.5273017646423, 442.127997401781, 8755.613162970645, 7289.760330658751, 876.8277953787522, 745.5310382819323, 2397.3125448347496, 3358.754019779379, 10398.71040365102, 1159.1877131962779, 590.7040208033077, 2422.0015174065334, 2513.047656660649, 3230.589008167095, 3205.1320492945088, 1627.1027160690567, 1559.9228437811564, 1247.3338458505605, 2981.5098284290334, 2315.3408541656145, 1298.4116266843096, 107273.48310947453, 3777.0262118852033, 1447.5762258189507, 1510.9380449315413, 1343.7582750182517, 9442.078147028642, 5042.9559296965435, 6940.98592504554, 9287.008981143206, 2038.0109124338983, 13737.999181365556, 3369.963492674614, 5015.560075806641, 5344.23624417894, 8718.828658095616, 1583.5076713298133, 1576.0484751585698, 1124.8713258069433, 1713.6479462685045, 991.4321303900073, 963.3249370937687, 1004.3430679817116, 1143.0090320891056, 790.8766296180141, 689.9227791037927, 669.3646850207656, 661.5769300725368, 640.522346583744, 610.1981404429873, 601.4447537134371, 586.7284554483181, 569.4293524380465, 573.8229954568717, 555.8273311729466, 550.4267000927587, 541.0610495719849, 499.4257485118045, 477.4562008473961, 466.482740564377, 464.24781443959245, 459.0557397385424, 452.2551485038991, 446.2056371711874, 437.81170627156365, 439.41657329154884, 866.1694314863191, 616.7207593772633, 551.7132500128972, 964.4050694064413, 1404.1354679313072, 817.381115150473, 9442.078147028642, 4888.288143463256, 690.3785104681871, 855.8718352716319, 16870.994069531782, 2578.5886903284063, 2487.5598999863482, 2146.502487784097, 107273.48310947453, 2136.79621646589, 1718.1564497958368, 5419.426037629178, 2998.3238897253523, 4682.102530622856, 1505.184372882886, 6940.98592504554, 3745.2272827082893, 7056.837933399104, 9710.08838552199, 2649.335500571514, 9287.169781874129, 6471.135036164916, 5015.560075806641, 4038.7270855830448, 2281.396698882755, 5190.446828714766, 1234.9883541501345, 1213.211375549753, 1215.3754517934992, 991.444601861986, 833.8010102230514, 758.0946439868127, 737.804144241456, 651.7590705299912, 640.5741948757524, 569.0422768077175, 565.9289314226568, 563.2520981422729, 518.4271671456619, 500.1512620506011, 472.27436465314395, 461.6469803734314, 454.2181787831791, 445.35094826134747, 433.9783391175045, 407.3308137834483, 388.0701648495108, 367.06024453348056, 365.03345680710504, 361.4943830630738, 360.03105321947106, 347.7393441844142, 351.93176001965537, 331.8521311703286, 325.52816440029807, 317.672046455423, 5509.382072662131, 2330.7147165345345, 1101.8952279598536, 856.703210367063, 791.3595322848225, 711.5556442590439, 638.4937552686846, 1449.5106389862196, 1040.3019566796477, 706.2570932875337, 709.7551450300034, 553.9111499006812, 2774.9163762842636, 692.819936178643, 3032.5232923326766, 4735.048809182113, 2948.1948351795345, 1385.3000237190672, 907.2834551842031, 5603.986739880363, 1125.5914972297035, 3745.2272827082893, 2453.3712611536075, 1662.6172871059869, 107273.48310947453, 1276.8515772503217, 6452.213308161425, 2312.4272168051134, 9543.787681173608, 8718.828658095616, 2008.3387341817759, 1749.134979370214, 9287.008981143206, 1929.00860339672, 1914.678233834912, 1104.591096261337, 1001.6161899947881, 847.9051963233202, 710.5503274172578, 638.2064133873514, 611.1037997023834, 615.4323029975168, 580.3656481686503, 606.2881165280851, 536.2872117508504, 506.35175591023125, 734.7575500935067, 550.5352145756419, 464.24761378465786, 448.23096439241925, 428.65737114403277, 424.74469723875416, 421.8372966955431, 415.3323471808573, 415.4685100748246, 400.383839842477, 387.930613521506, 374.8961931525301, 550.4512392560785, 363.7489874603586, 351.6385911766825, 341.9081074109041, 325.51471631207414, 637.6874288210737, 1280.9462204241163, 671.4681159933186, 562.1042632233265, 876.7267873709153, 1209.9145941321285, 447.59226629205324, 792.457534510736, 473.18836987539066, 14573.547903922637, 801.9792029559229, 546.3293362014217, 1846.8419311455696, 877.4479328081482, 1163.4799442347075, 1425.327766573778, 1792.5223813432463, 1464.576226070937, 2387.384696668256, 107273.48310947453, 2205.2686359711897, 8718.828658095616, 3369.963492674614, 1302.0842874871523, 1226.409516381689, 2381.3485691697197, 1510.397410429472, 10398.71040365102, 6452.213308161425, 9287.008981143206, 2874.9705962751905, 2773.975091654699, 1639.9659880261065], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.8546, -5.6596, -5.7737, -5.8352, -5.8734, -5.8767, -6.061, -6.0841, -6.1619, -6.1711, -6.2279, -6.2751, -6.3461, -6.3444, -6.3506, -6.3958, -6.3999, -6.4046, -6.3949, -6.45, -6.4729, -6.4749, -6.4811, -6.5188, -6.5279, -6.5582, -6.5706, -6.5897, -3.4973, -6.6016, -6.0045, -4.2541, -5.6886, -5.1373, -4.9257, -4.0058, -4.444, -4.8474, -5.5615, -3.9278, -5.4643, -4.4189, -4.9923, -4.0054, -4.4622, -4.8763, -4.7667, -4.8043, -4.591, -3.829, -2.5415, -5.3738, -5.0753, -4.631, -5.0379, -5.2051, -4.3498, -5.5011, -4.7044, -5.0532, -4.9127, -5.2077, -5.1247, -5.1706, -5.1478, -5.192, -5.2906, -5.5064, -5.7044, -5.5442, -5.8846, -5.9095, -5.9198, -5.9718, -5.9909, -5.9632, -6.0041, -6.0428, -6.1151, -6.1214, -6.1202, -6.1249, -6.1736, -6.1803, -6.1909, -6.2889, -6.3143, -6.3235, -6.3288, -6.3507, -6.3871, -6.3935, -6.3928, -6.0542, -6.4139, -6.0103, -5.9542, -5.3701, -5.2044, -5.8631, -4.6814, -5.6464, -6.1625, -6.2455, -5.7261, -3.7464, -4.1202, -5.0779, -5.7596, -5.6268, -5.6413, -2.8622, -5.4419, -4.8188, -5.5869, -4.7161, -5.2981, -4.8263, -4.9691, -5.2303, -5.5962, -4.5424, -4.8537, -5.5186, -5.4757, -5.3859, -5.2036, -5.5635, -5.4579, -5.3093, -5.0798, -5.3892, -5.3711, -5.4314, -5.4848, -5.4862, -4.3855, -5.1492, -4.3449, -4.9725, -5.4532, -5.4745, -4.1898, -5.7367, -5.7546, -5.7792, -5.7848, -5.8108, -5.8117, -5.8617, -5.9869, -5.9919, -6.0144, -6.1672, -6.2011, -6.0516, -6.26, -6.266, -6.2739, -6.2993, -6.3279, -6.3365, -6.3446, -6.355, -6.3838, -6.3688, -3.3832, -3.5666, -5.6941, -5.8589, -4.7379, -4.4157, -3.3538, -5.4413, -6.094, -4.8113, -4.8101, -4.5944, -4.6427, -5.2282, -5.2741, -5.4625, -4.7685, -5.01, -5.4439, -2.2944, -4.6789, -5.393, -5.3999, -5.489, -4.5462, -4.8652, -4.7164, -4.6617, -5.3229, -4.8453, -5.2193, -5.2177, -5.3112, -5.3124, -4.9671, -4.9718, -5.3093, -4.8883, -5.4357, -5.4644, -5.4227, -5.2935, -5.6619, -5.7986, -5.8289, -5.8406, -5.873, -5.9215, -5.936, -5.9608, -5.9908, -5.9831, -6.015, -6.0248, -6.0421, -6.1222, -6.1672, -6.1905, -6.1953, -6.2066, -6.2216, -6.235, -6.2541, -6.2504, -5.5749, -5.913, -6.0236, -5.4763, -5.174, -5.6753, -3.5245, -4.1164, -5.8491, -5.6736, -3.3242, -4.9062, -4.9419, -5.0729, -2.5516, -5.1504, -5.3427, -4.7759, -5.1163, -4.9271, -5.4723, -4.8063, -5.0792, -4.8365, -4.7332, -5.2478, -4.8378, -5.1306, -5.2282, -5.3172, -5.408, -5.3665, -5.0779, -5.0957, -5.094, -5.2977, -5.471, -5.5663, -5.5935, -5.7176, -5.7349, -5.8535, -5.859, -5.8638, -5.9468, -5.9828, -6.0402, -6.063, -6.0793, -6.099, -6.1249, -6.1884, -6.237, -6.2928, -6.2983, -6.3081, -6.3121, -6.347, -6.3351, -6.3938, -6.4131, -6.4376, -3.5847, -4.4459, -5.1965, -5.4458, -5.5251, -5.6341, -5.7423, -4.936, -5.2658, -5.648, -5.6477, -5.8911, -4.365, -5.6831, -4.3498, -4.0854, -4.4937, -5.1427, -5.5053, -4.1491, -5.3842, -4.633, -4.9172, -5.2184, -3.0793, -5.3879, -4.6466, -5.1962, -4.6934, -4.8681, -5.3412, -5.3868, -5.3029, -4.5864, -4.5939, -5.1443, -5.2422, -5.409, -5.5859, -5.6934, -5.7368, -5.7298, -5.7885, -5.7449, -5.8676, -5.9252, -5.5529, -5.8417, -6.0121, -6.0473, -6.092, -6.1012, -6.1081, -6.1237, -6.1234, -6.1604, -6.1921, -6.2263, -5.8423, -6.2566, -6.2905, -6.3187, -6.3679, -5.6955, -5.0062, -5.6458, -5.822, -5.3846, -5.0684, -6.051, -5.4992, -5.9986, -2.827, -5.5121, -5.8739, -4.9442, -5.534, -5.349, -5.2459, -5.0976, -5.2613, -4.9631, -2.6804, -5.0632, -4.501, -4.9685, -5.4323, -5.4687, -5.2621, -5.4465, -4.9517, -5.1292, -5.0929, -5.3491, -5.4382, -5.5111], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5635, 1.563, 1.5629, 1.5629, 1.5629, 1.5629, 1.5626, 1.5626, 1.5625, 1.5625, 1.5624, 1.5624, 1.5623, 1.5622, 1.5622, 1.5622, 1.5622, 1.5622, 1.5621, 1.5621, 1.562, 1.562, 1.562, 1.562, 1.5619, 1.5619, 1.5619, 1.5618, 1.5618, 1.5618, 1.5618, 1.5431, 1.5569, 1.547, 1.5004, 1.4466, 1.4601, 1.4029, 1.4722, 1.1443, 1.3994, 1.2071, 1.2974, 1.0222, 1.1161, 1.2122, 1.1026, 1.1006, 1.0198, 0.6461, 0.0839, 1.2358, 1.092, 0.8025, 1.0281, 1.0487, 0.3308, 1.2689, 0.3678, 0.7039, 0.434, 0.8436, 0.5636, 0.4833, 0.2155, 1.5984, 1.5984, 1.5983, 1.5981, 1.5981, 1.5979, 1.5979, 1.5979, 1.5978, 1.5978, 1.5978, 1.5978, 1.5978, 1.5977, 1.5977, 1.5977, 1.5977, 1.5976, 1.5976, 1.5976, 1.5974, 1.5974, 1.5974, 1.5974, 1.5973, 1.5973, 1.5973, 1.5973, 1.5972, 1.5972, 1.5957, 1.5949, 1.5833, 1.5757, 1.5881, 1.5534, 1.5776, 1.585, 1.5901, 1.4698, 0.9342, 0.9247, 1.2418, 1.4496, 1.3953, 1.3383, -0.2368, 1.2149, 0.806, 1.2829, 0.6306, 1.0404, 0.61, 0.6848, 0.9241, 1.2539, 0.0792, 0.2816, 1.0661, 1.0003, 0.8588, 0.4792, 1.1137, 0.7965, 0.268, -0.6047, 0.3565, 0.0623, -0.3592, 0.0935, -0.4141, 1.7498, 1.7495, 1.7494, 1.7493, 1.7493, 1.7493, 1.7491, 1.7491, 1.749, 1.749, 1.749, 1.749, 1.749, 1.7489, 1.7488, 1.7488, 1.7487, 1.7485, 1.7485, 1.7484, 1.7484, 1.7484, 1.7483, 1.7483, 1.7482, 1.7482, 1.7482, 1.7482, 1.7482, 1.7481, 1.7479, 1.7476, 1.7381, 1.7355, 1.6885, 1.6735, 1.6053, 1.7117, 1.7332, 1.6049, 1.5692, 1.5337, 1.4933, 1.5858, 1.582, 1.6172, 1.4399, 1.4512, 1.5957, 0.331, 1.2929, 1.5378, 1.4882, 1.5163, 0.5094, 0.8176, 0.6469, 0.4105, 1.2659, -0.1647, 0.8666, 0.4705, 0.3136, -0.1772, 1.8741, 1.874, 1.8738, 1.8738, 1.8737, 1.8737, 1.8737, 1.8736, 1.8735, 1.8734, 1.8733, 1.8733, 1.8733, 1.8732, 1.8732, 1.8731, 1.8731, 1.8731, 1.8731, 1.8731, 1.8729, 1.8729, 1.8728, 1.8728, 1.8728, 1.8727, 1.8727, 1.8727, 1.8727, 1.8727, 1.8696, 1.8711, 1.8719, 1.8607, 1.7873, 1.8271, 1.5311, 1.5975, 1.8222, 1.7828, 1.151, 1.4473, 1.4476, 1.4641, 0.0737, 1.3911, 1.4168, 0.8349, 1.0864, 0.8299, 1.4195, 0.557, 0.9011, 0.5103, 0.2944, 1.0787, 0.2344, 0.3028, 0.46, 0.5877, 1.068, 0.2875, 2.0118, 2.0118, 2.0117, 2.0117, 2.0115, 2.0114, 2.0114, 2.0112, 2.0112, 2.011, 2.011, 2.011, 2.0109, 2.0108, 2.0107, 2.0107, 2.0107, 2.0106, 2.0106, 2.0105, 2.0103, 2.0102, 2.0102, 2.0102, 2.0102, 2.0101, 2.01, 2.01, 2.0099, 2.0099, 2.0096, 2.0087, 2.0072, 2.0096, 2.0097, 2.007, 2.0071, 1.9935, 1.9954, 2.0005, 1.9959, 2.0004, 1.9151, 1.9846, 1.8415, 1.6604, 1.7259, 1.8321, 1.8928, 1.4282, 1.7982, 1.3473, 1.4861, 1.574, -0.454, 1.6684, 0.7897, 1.2663, 0.3515, 0.2672, 1.2623, 1.3548, -0.2307, 2.0573, 2.0573, 2.057, 2.0569, 2.0568, 2.0566, 2.0565, 2.0564, 2.0564, 2.0563, 2.0563, 2.0562, 2.0561, 2.0561, 2.056, 2.056, 2.0559, 2.0558, 2.0558, 2.0558, 2.0558, 2.0558, 2.0557, 2.0556, 2.0555, 2.0555, 2.0555, 2.0554, 2.0553, 2.0552, 2.0551, 2.047, 2.0533, 2.0549, 2.0477, 2.0418, 2.0537, 2.0342, 2.0504, 1.7945, 2.0094, 2.0314, 1.7431, 1.8975, 1.8003, 1.7005, 1.6196, 1.6579, 1.4675, -0.055, 1.4468, 0.6343, 1.1174, 1.6045, 1.628, 1.171, 1.4419, 0.0074, 0.3071, -0.0207, 0.8956, 0.8423, 1.295]}, \"token.table\": {\"Topic\": [6, 3, 5, 6, 2, 3, 5, 3, 3, 6, 1, 1, 2, 3, 4, 5, 6, 2, 6, 2, 3, 6, 1, 2, 3, 4, 4, 4, 6, 1, 3, 5, 4, 4, 3, 1, 5, 5, 3, 4, 5, 3, 6, 1, 2, 5, 5, 2, 3, 5, 6, 1, 5, 6, 3, 6, 1, 2, 3, 3, 4, 1, 2, 3, 4, 1, 2, 3, 5, 6, 4, 2, 2, 1, 2, 3, 4, 5, 6, 6, 4, 3, 4, 1, 2, 3, 4, 5, 6, 5, 3, 4, 3, 4, 1, 2, 3, 4, 5, 2, 4, 5, 5, 1, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 4, 5, 1, 5, 1, 2, 6, 3, 5, 2, 1, 2, 3, 4, 6, 3, 4, 5, 6, 1, 2, 2, 3, 4, 6, 5, 5, 6, 1, 1, 2, 3, 4, 6, 4, 1, 5, 1, 3, 4, 5, 6, 5, 2, 4, 5, 5, 1, 2, 5, 6, 4, 5, 1, 2, 6, 1, 2, 4, 5, 6, 2, 6, 3, 6, 5, 6, 3, 5, 1, 2, 3, 6, 5, 4, 6, 1, 3, 4, 5, 6, 4, 6, 2, 1, 2, 3, 4, 4, 4, 1, 2, 6, 1, 2, 6, 3, 3, 5, 2, 4, 6, 1, 2, 6, 1, 2, 3, 4, 6, 2, 4, 2, 1, 2, 3, 4, 5, 6, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 1, 5, 2, 6, 2, 3, 6, 4, 5, 6, 1, 1, 2, 3, 5, 6, 2, 4, 5, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 2, 4, 3, 6, 2, 2, 2, 3, 3, 2, 3, 5, 6, 5, 3, 6, 5, 2, 3, 4, 6, 2, 3, 6, 2, 4, 2, 3, 4, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 2, 2, 2, 3, 4, 5, 6, 2, 3, 4, 1, 2, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 3, 2, 3, 4, 5, 6, 3, 5, 3, 1, 3, 4, 6, 1, 5, 4, 4, 2, 6, 2, 1, 2, 3, 5, 4, 1, 3, 6, 6, 6, 6, 2, 3, 5, 1, 2, 4, 1, 2, 3, 5, 6, 4, 1, 3, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 4, 1, 3, 4, 5, 1, 3, 5, 6, 1, 5, 1, 2, 3, 1, 1, 2, 3, 4, 5, 6, 2, 3, 5, 1, 2, 3, 4, 5, 6, 5, 2, 5, 6, 1, 3, 2, 4, 5, 6, 5, 5, 1, 2, 6, 1, 2, 5, 2, 3, 3, 1, 2, 5, 5, 2, 3, 5, 6, 1, 3, 5, 2, 1, 5, 6, 2, 3, 1, 5, 5, 4, 2, 6, 1, 5, 4, 5, 3, 6, 1, 6, 1, 3, 4, 6, 3, 1, 2, 3, 5, 6, 6, 1, 4, 6, 3, 4, 5, 1, 2, 3, 4, 6, 2, 6, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 4, 4, 6, 1, 2, 3, 2, 4, 3, 6, 2, 3, 4, 5, 1, 2, 3, 5, 6, 6, 1, 2, 3, 4, 6, 5, 1, 1, 2, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 5, 1, 2, 3, 5, 6, 2, 4, 6, 3, 1, 2, 5, 2, 3, 5, 6, 2, 6, 3, 3, 6, 1, 2, 3, 1, 2, 3, 6, 3, 1, 3, 1, 2, 3, 4, 5, 6, 1, 2, 4, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 6, 1, 3, 3, 5, 6, 1, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 6, 1, 2, 3, 4, 5, 6, 1, 1, 2, 3, 4, 5, 6, 1, 1, 5, 3, 1, 3, 4, 6, 1, 3, 2, 5, 2, 6, 6, 2, 3, 6, 2, 5, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3, 6, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 1, 1, 5, 1, 2, 4, 5, 1, 1, 2, 3, 4, 6, 5, 1, 2, 3, 4, 1, 1, 2, 5, 1, 2, 3, 4, 5, 6, 4, 2, 3, 4, 6, 3, 1, 4, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 5, 2, 1, 2, 3, 4, 5, 6, 2, 3], \"Freq\": [0.9967920938739762, 0.9974487084997788, 0.9728357467851642, 0.025980776620375304, 0.9988915301631377, 0.004216114402583309, 0.9950029990096608, 0.9988715842786222, 0.45948171998167386, 0.5402551635519393, 0.9983215439835992, 0.17571639856449298, 0.5095461217764635, 0.052390100943498205, 0.06024861608502294, 0.1899665060211245, 0.012154503418891583, 0.9983762590059587, 0.9973440015278352, 0.0012618972707697214, 0.021452253603085263, 0.9767084875757643, 0.9985466253049595, 0.2411887281187769, 0.0008182823685115416, 0.7579340438338155, 0.9989651480700166, 0.9992459952473327, 0.9972537274525693, 0.42649653045564356, 0.05545598318257028, 0.517970317148543, 0.998758445339486, 0.9972980234431129, 0.9986801681978824, 0.9979570453887009, 0.9985560589360506, 0.9986323907473064, 0.013479813008449925, 0.9861001670027599, 0.9995515615686937, 0.002978547979216188, 0.9948350250582068, 0.00036301711764085386, 0.00235961126466555, 0.9970265136006051, 0.99910362471616, 0.0031226915979935643, 0.00702605609548552, 0.0007806728994983911, 0.9891125636644614, 0.31951882162549977, 0.2134190602460399, 0.46647308882348726, 0.9978845685997385, 0.9976094898563949, 0.2868212710910126, 0.6996189436023914, 0.01312254181462149, 0.9977599326734085, 0.002170036483607459, 0.6238943886672242, 0.036055816063327716, 0.054727577953265286, 0.2849053322861163, 0.10670607709870732, 0.26604420573934456, 0.32985155589634185, 0.000720987007423698, 0.29668615355485173, 0.9992605244111099, 0.9985688697062378, 0.999505462926583, 0.00029673911962955346, 0.04747825914072855, 0.41335759364396796, 0.005934782392591069, 0.1427315165418152, 0.39050868143249234, 0.9984664415258314, 0.9977001927061326, 0.04526652171696995, 0.9530437950680971, 0.6999468342087612, 0.2156420787404401, 0.00374703872702763, 0.004871150345135919, 0.009180244881217693, 0.06669728934109181, 0.9981683666571057, 0.9988439399439364, 0.9985115320414332, 0.9983240106947696, 0.998891572231136, 0.1229872211276307, 0.04730277735678104, 0.3256422778035242, 0.03136921024712848, 0.4720319256234571, 0.9990858848890554, 0.9994551773809903, 0.9988682906245395, 0.9990015131953374, 0.17969454214844227, 0.12021522982891127, 0.14576620202251261, 0.5541628887235178, 0.9981096815042202, 0.22764246384242925, 0.1594895542129452, 0.24192371914982488, 0.16515731088846514, 0.08488584257777071, 0.12089660579739823, 0.9968946730700102, 0.0018125357692182005, 0.004537636494948293, 0.9946499196926657, 0.9979916126373296, 0.9990386923690612, 0.9988723331288327, 0.8754673046295494, 0.12426504781829685, 0.9983444294944664, 0.9989972264822921, 0.21840736693803475, 0.7697205083301043, 0.003309202529364163, 0.008603926576346824, 0.2891312651186977, 0.7092718250915452, 0.00010590888832186728, 0.0013768155481842746, 0.9985702173855638, 0.9984502037533793, 0.0001371787211980443, 0.9975636605521782, 0.0021948595391687088, 0.0001371787211980443, 0.9991760324829932, 0.02562556881411628, 0.9737716149364186, 0.9974939232796515, 0.22050559542901138, 0.32639587237064094, 0.3936183515526867, 0.059290623231361875, 0.00019829639876709656, 0.9981459923068842, 0.9981356725530587, 0.9973016433909558, 0.004209558068473528, 0.0028063720456490185, 0.011225488182596074, 0.2813387975763141, 0.6994882323780178, 0.9989100844069089, 0.0034635256001266353, 0.9951863557697199, 0.0011545085333755452, 0.9977770200121712, 0.06303684612856726, 0.7291478490335307, 0.20275769064034008, 0.0051989151446241045, 0.01634140923300696, 0.9833683320803599, 0.0017071356443495638, 0.9918458093670965, 0.0051214069330486915, 0.0064446215607195335, 0.0006783812169178457, 0.24150371322275305, 0.7506288165195962, 0.00033919060845892285, 0.0022341762253494826, 0.9964425965058693, 0.0015681664006592581, 0.9973538308192882, 0.9983775155023189, 0.9992975620626164, 0.9987473846055618, 0.9974321961792939, 0.016649437946122805, 0.8158224593600174, 0.1672511720951427, 0.9980151193313108, 0.9991997056921119, 0.9972246894080671, 0.9994771389847904, 0.7204340571363306, 0.0035069808066441684, 0.23246272775469914, 0.0395787833892699, 0.004007978064736193, 0.9990519854805922, 0.9981839559345702, 0.9990841037072791, 0.5803197567718509, 0.06587413455248037, 0.00018452138530106546, 0.35354297423684145, 0.9980389466718695, 0.9980364731329442, 0.006523106591346933, 0.342463096045714, 0.6506798824868566, 0.93867380858188, 0.015012108888915007, 0.04628733574082127, 0.9993332999472255, 0.9993464635953562, 0.998358572302848, 0.9891755854312411, 0.010461316414666475, 0.9982467179847202, 0.9836123807816135, 0.015115887300705367, 0.001079706235764669, 0.3580126144482116, 0.020591575210093215, 0.0009359806913678734, 0.6168112756114286, 0.0037439227654714937, 0.9974197788716043, 0.002714067425500964, 0.9993966344131092, 0.3994429713048335, 0.11042621391020994, 0.002430206532645522, 0.484974386587943, 0.0007705532908388242, 0.001956019892129323, 0.9991844990474884, 0.6573585003167699, 0.13362520866390032, 0.0024765348906282893, 0.1939234494791978, 0.009044736122294622, 0.003553289190901459, 0.4231005167109122, 0.1789794210013854, 0.00042715852267633745, 0.35176504342396386, 0.03310478550741615, 0.012601176418951955, 0.006956592886867081, 0.47722227203908174, 0.011826207907674037, 0.19130630438884472, 0.3126988502646753, 0.27999768040971995, 0.5868712289215945, 0.0009773042946238043, 0.0034205650311833155, 0.11581055891292082, 0.012704955830109457, 0.9788450838134715, 0.017595133956911976, 0.0037042387277709424, 0.9977546195086028, 0.9988353510302911, 0.9984243937918124, 0.9990278286266311, 0.4534594940899818, 0.0036276759527198547, 0.5427910144257082, 0.009124849514396615, 0.0011406061892995768, 0.9900461723120326, 0.9992269524682136, 0.0017844439082690417, 0.26427614281464507, 0.1746970586195392, 0.5574602769432486, 0.0017844439082690417, 0.3702068358270915, 0.4545873128219151, 0.1750978277560568, 0.005571739380804886, 0.8054258816030174, 0.18882005679394334, 0.00030954107671138256, 0.851358420146567, 0.04896884914565299, 0.016089764719285984, 0.0013991099755900854, 0.026233312042314102, 0.05631417651750094, 0.8481380605938221, 0.1505073633803203, 0.0006459543492717609, 0.0006459543492717609, 0.99912871755866, 0.9992247830770441, 0.001360993160087621, 0.9989689795043137, 0.998900385814442, 0.9984279199896368, 0.0005604670589781604, 0.99931276615806, 0.9981816957541296, 0.07056188056771345, 0.9262363309964411, 0.0020841061771054606, 0.0008931883616166259, 0.9990393268738819, 0.9985961260020002, 0.9973126113142791, 0.9967328428431741, 0.7702661069932287, 0.00942886948296796, 0.0036264882626799847, 0.21613870045572708, 0.9768158111886388, 0.0011883404029058868, 0.021984297453758905, 0.9988316916078398, 0.9992253995750863, 0.017451406720576615, 0.3300254915380155, 0.6522948023113303, 0.6811617235338246, 0.09925949556506775, 0.0005251825162172896, 0.2190011092626098, 0.3230908831289796, 0.37977349420423917, 0.007085326384407448, 0.25549686942173255, 0.012045054853492661, 0.022531337902415682, 0.9985218334918318, 0.9987458346008721, 0.1201955280593882, 0.029350070805199444, 0.6634047750254605, 0.09969706590972509, 0.08711846413606819, 0.0034540495421381376, 0.8089384027687518, 0.18720948518388705, 0.9991884547052822, 0.9987159598548215, 0.2823574358442187, 0.07706697072453969, 0.6344737676028913, 0.004650593060963602, 0.001328740874561029, 0.9996457713766592, 0.26682952153420064, 0.45245005825364454, 0.23782631267178753, 0.003929467007165647, 0.027880504003222926, 0.011039931115370152, 0.2340209459565441, 0.2589328531067569, 0.023402094595654413, 0.4510565006743068, 0.0267991728434107, 0.006039250218233396, 0.5496632832922519, 0.0004383279771070589, 0.44621788069498597, 0.0004383279771070589, 0.0035066238168564713, 0.9980155027481289, 0.6153705914686589, 0.0053603710058245544, 0.34252770727218906, 0.030554114733199963, 0.0058964081064070105, 0.7918090774068336, 0.20762662838017534, 0.998162040891943, 0.8893715473152802, 0.00015749451873831773, 0.11024616311682242, 0.00015749451873831773, 0.01549830258649974, 0.9834377459433471, 0.9993347443463221, 0.9990445179126664, 0.26964949820643164, 0.7298946256672085, 0.9988018248770626, 0.005913349815043713, 0.288698185613027, 0.0021119106482298975, 0.7030550547957329, 0.9991172142469763, 0.14473793287489373, 0.003419006288383316, 0.8524722345702401, 0.99760108254139, 0.9993053131422465, 0.9979409222123533, 0.01140474794789144, 0.9876511722873987, 0.9973180756735838, 0.9986648900399279, 0.000583550432384619, 0.9990383402424676, 0.006618963861392401, 0.15806085701005054, 0.6330377037035693, 0.046862264138658204, 0.1551485129110379, 0.9991279471119503, 0.9975688228480614, 0.9980088518962861, 0.3394698102391116, 0.4009288735003355, 0.20460666201699007, 0.021963426996174075, 0.03313780213457843, 0.9994635514741518, 0.0040389623683773, 0.8652034387688231, 0.00028849731202695004, 0.0017309838721617002, 0.12866980116401971, 0.013450879009841732, 0.12594913981942712, 0.26983278498530994, 0.5906158692503234, 0.9986627398301154, 0.00041713376178446166, 0.9402194990621766, 0.0008342675235689233, 0.05798159288804017, 0.0008884217786481079, 0.0008884217786481079, 0.806686975012482, 0.1918991041879913, 0.9977403577624584, 0.997136210306719, 0.007701717848550472, 0.13478006234963327, 0.8572011965436676, 0.9980381248374344, 0.05625976431077382, 0.37196538387288475, 0.0860169950206046, 0.017668355733962027, 0.2944725955660338, 0.17373883138395993, 0.13047060364287927, 0.8649870716197218, 0.004128816570977192, 0.2913815867327852, 0.5144126089034706, 0.14740137725053462, 0.00240209651815686, 0.04411122696978962, 0.0003639540179025546, 0.998598538708283, 0.9995028517949195, 0.6447665426755924, 0.3542607216753022, 0.9015429851183302, 0.09846709881369249, 0.9980024976379347, 0.9125198047347014, 0.001168399237816519, 0.08646154359842241, 0.9978844646139888, 0.9976981722571668, 0.9926302484002671, 0.005677580067113062, 0.0009462633445188438, 0.03504469448978883, 0.7079028286937343, 0.2567820341706345, 0.9864104357189575, 0.012505996015454294, 0.9983138746309345, 0.004324454640347949, 0.08829094890710397, 0.9070543608129824, 0.997168870995704, 0.8614527217798746, 0.008213002644087789, 0.12958293060671844, 0.9990413203424293, 0.9990826848371863, 0.8487478917965179, 0.15118898000140724, 0.9997079063715643, 0.0054160310738245905, 0.9875229991273504, 0.0054160310738245905, 0.015236056778081108, 0.9835721097850137, 0.004698558091202583, 0.9945281293045468, 0.9971115244724252, 0.9986624892933795, 0.998719705730432, 0.9981937606951209, 0.0012636481386820327, 0.9970183814201239, 0.9996794007765134, 0.9973524412243915, 0.9990570568772218, 0.0007685054283670937, 0.001816691341001386, 0.997363546209761, 0.034506921997737784, 0.9627431237368842, 0.0017253460998868893, 0.0017253460998868893, 0.9987892796559348, 0.1428478953224718, 0.03532797411200915, 0.04223996904696747, 0.1436158947596894, 0.6359035340161647, 0.9978754052850953, 0.766239467001903, 0.017100310991970298, 0.21648266043026226, 0.8455546408967418, 0.0019231720414634005, 0.15257164862276312, 0.0021839973805574692, 0.2193357369331287, 0.773447072343138, 0.0015599981289696207, 0.003431995883733166, 0.014877083132393651, 0.9843670005933799, 0.9987827367270348, 0.15839283625762188, 0.26781120395477703, 0.14554707401225356, 0.012845762245368321, 0.1745647333700945, 0.24085804210065603, 0.040584986844932974, 0.0026700649240087486, 0.06488257765341258, 0.37781418674723793, 0.5142545043640849, 0.11975543558499165, 0.8788068054958785, 0.0009004168089097116, 0.0009004168089097116, 0.9995039993560124, 0.9995641351770219, 0.9165782286634485, 0.08332529351485896, 0.998563423081276, 0.013413257780715455, 0.985874446882586, 0.36667208045859906, 0.6326548435849162, 0.998590877101281, 0.9975997716845645, 0.149380550891513, 0.0013190335619559649, 0.006595167809779824, 0.8428624460898615, 0.00539741957851601, 0.1310100934057977, 0.6162871809651007, 0.01521090972127239, 0.23208904187618842, 0.9993699693119259, 0.7036061733061005, 0.03837851854396912, 0.0005950157913793663, 0.2573443297715759, 0.9992254912903099, 0.9992119736968843, 0.9972042199664174, 0.9125693989013881, 0.08727593244526699, 0.9982943541506968, 0.9985657677308376, 0.8872640577762582, 0.11242352036419669, 0.5853173077879132, 0.221966752406649, 0.10414691659446966, 0.03112770970840294, 0.0017454790490693238, 0.055564416395373475, 0.00216223021579381, 0.05492064748116278, 0.20714165467304702, 0.033298345323224676, 0.47396086330200315, 0.2287639568309851, 0.9972423418586539, 0.5974445227739963, 0.06142937220061654, 0.0017551249200176153, 0.16533276746565936, 0.17410839206574744, 0.22600394169170948, 0.1037842874233832, 0.6705011200642257, 0.998695275254533, 0.9984951810456474, 0.01862697607992975, 0.9810207402096335, 0.014325235697215942, 0.8344449793628286, 0.006366771420984863, 0.14444612661359407, 0.0017790293819612887, 0.9962564538983216, 0.999102096785331, 0.9987400437561735, 0.999384804278382, 0.9989216705532192, 0.9842101000544986, 0.01483733819177636, 0.0012469151273676613, 0.027432132802088546, 0.018703726910514917, 0.9526431573088932, 0.9972379869489402, 0.0002992569096454328, 0.9992188213061002, 0.6306128691935965, 0.21601895935998908, 0.011231074214512707, 0.10824843870583524, 0.033454263617697426, 0.0007168770775220877, 0.0014484807751646846, 0.04924834635559928, 0.9487549077328685, 0.0016214793888400232, 0.9972098241366143, 0.0016214793888400232, 0.0011672653818719089, 0.0011672653818719089, 0.9968446361186102, 0.4867433038567057, 0.24165171092532564, 0.013759528024217831, 0.2038130088587266, 0.03325219272519309, 0.020925948870164617, 0.9979716180894714, 0.0019130446353152807, 0.28977526173933915, 0.7087746266867619, 0.000783176383079295, 0.006298951860386359, 0.0004199301240257573, 0.4010332684445982, 0.18015002320704987, 0.4119514516692679, 0.6291586299729318, 0.06809076081958136, 0.0017332193663166164, 0.2760770847775753, 0.001980822132933276, 0.022779454528732673, 0.639120768560978, 0.22185243000355917, 0.007859506376937683, 0.12307272485704691, 0.0005358754347912056, 0.007680881232007282, 0.0063399698534222625, 0.9932619437028212, 0.5818690598557584, 0.07662134168720075, 0.029247931504254053, 0.2059713486215074, 0.03851664219222189, 0.06786755937078669, 0.9990487522228866, 0.3678552289503327, 0.03389451974068106, 0.2781344414014711, 0.24304364449347185, 0.07317228673429382, 0.003987590557727184, 0.9987876356698758, 0.9976645157305576, 0.00130413662187001, 0.9989472609624817, 0.21229416220188232, 0.007735414817072635, 0.00601643374661205, 0.7726819911720332, 0.998827463979129, 0.9987127118336573, 0.0034324235150902317, 0.9962609252549397, 0.9981912708764838, 0.9994648732337806, 0.998418761775487, 0.9980051128078924, 0.9992184681408124, 0.998932432154862, 0.9960570842351965, 0.0025638534986748944, 0.9998783367572175, 0.997312180260668, 0.18010307175712814, 0.07040000167005248, 0.7415754777146019, 0.0025914111044191097, 0.005614724059574738, 0.005366408605277162, 0.020124032269789358, 0.7331855756959923, 0.00033540053782982264, 0.21130233883278826, 0.029850647866854214, 0.21875249740263408, 0.003087786192948097, 6.861747095440216e-05, 0.009469210991707498, 0.7685842921602586, 0.34197620424724723, 0.012273207982772332, 0.6454591652757995, 0.3441123166540423, 0.0032160029593835725, 0.6524466003849423, 0.06514550448958228, 0.5090882838649308, 0.2774245142410016, 0.07372564410528336, 0.0012711317949186786, 0.07340786115655369, 0.9995515927704858, 0.9988344365511702, 0.011327319861328478, 0.9883086579009096, 0.9793905665376009, 0.013784838847975314, 0.006003074982182798, 0.0006670083313536443, 0.9974809189470705, 0.7446110180073675, 0.02999617845053376, 0.014704009044379294, 0.208796928430186, 0.0011763207235503436, 0.9977456498877479, 0.4057107952892274, 0.5718917707608036, 0.0015281009238765626, 0.020629362472333598, 0.9970322908454611, 0.0014437305751505503, 0.1631415549920122, 0.8351981377245934, 0.2596172963696331, 0.004466224299366607, 0.3317972439174612, 0.267829386210404, 0.11612183178353179, 0.02017004522294597, 0.9991475239050587, 0.9554202424821912, 0.00413303637699578, 0.03891942588337693, 0.0013776787923319267, 0.998281000851195, 0.9985120764083093, 0.9986246207870775, 0.9987108373579908, 0.4669968997882283, 0.21510909480649032, 0.010199138115824973, 0.20769153981316307, 0.05825871317675779, 0.0417237468374658, 0.31152165457322817, 0.44814163611661684, 0.012643494435892012, 0.22231477716443454, 0.0052681226816216715, 0.9978738552401993, 0.9982750579796574, 0.30235784262742715, 0.14105725564171281, 0.26197885723380704, 0.06331424909719628, 0.10606213496724207, 0.12512101607303075, 0.9983298859077979, 0.0014200994109641507], \"Term\": [\"accept\", \"active\", \"add\", \"add\", \"admit\", \"adult\", \"adult\", \"age\", \"ago\", \"ago\", \"air\", \"amp\", \"amp\", \"amp\", \"amp\", \"amp\", \"amp\", \"answer\", \"approve\", \"ass\", \"ass\", \"ass\", \"australian\", \"bad\", \"bad\", \"bad\", \"battle\", \"bed\", \"benefit\", \"biden\", \"biden\", \"biden\", \"bill\", \"birthday\", \"bit\", \"bitch\", \"blame\", \"block\", \"body\", \"body\", \"book\", \"boost\", \"boost\", \"booster\", \"booster\", \"booster\", \"border\", \"bring\", \"bring\", \"bring\", \"bring\", \"call\", \"call\", \"call\", \"campaign\", \"car\", \"care\", \"care\", \"care\", \"case\", \"case\", \"catch\", \"catch\", \"catch\", \"catch\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"challenge\", \"chance\", \"check\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"chinese\", \"choose\", \"class\", \"class\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"common\", \"completely\", \"concert\", \"condition\", \"confirm\", \"continue\", \"continue\", \"continue\", \"continue\", \"continue\", \"control\", \"corona\", \"coronavirus\", \"cough\", \"country\", \"country\", \"country\", \"country\", \"couple\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"crazy\", \"crazy\", \"crisis\", \"crisis\", \"cry\", \"cure\", \"d\", \"daily\", \"daily\", \"damn\", \"date\", \"datum\", \"datum\", \"datum\", \"datum\", \"day\", \"day\", \"day\", \"day\", \"dead\", \"deadly\", \"death\", \"death\", \"death\", \"death\", \"decision\", \"declare\", \"declare\", \"destroy\", \"die\", \"die\", \"die\", \"die\", \"die\", \"dog\", \"double\", \"drink\", \"drop\", \"drop\", \"drop\", \"drop\", \"drop\", \"drug\", \"eat\", \"eat\", \"eat\", \"economic\", \"effect\", \"effect\", \"effect\", \"effect\", \"emergency\", \"emergency\", \"employee\", \"employee\", \"employee\", \"end\", \"end\", \"end\", \"end\", \"end\", \"enter\", \"enter\", \"entire\", \"entire\", \"episode\", \"evidence\", \"exactly\", \"excuse\", \"expert\", \"expert\", \"expert\", \"extend\", \"fact\", \"fake\", \"fall\", \"family\", \"family\", \"family\", \"family\", \"family\", \"fatigue\", \"fauci\", \"federal\", \"feel\", \"feel\", \"feel\", \"feel\", \"feeling\", \"fever\", \"fight\", \"fight\", \"fight\", \"finally\", \"finally\", \"finally\", \"fire\", \"flu\", \"focus\", \"force\", \"force\", \"fraud\", \"friend\", \"friend\", \"friend\", \"fuck\", \"fuck\", \"fuck\", \"fuck\", \"fuck\", \"future\", \"future\", \"game\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"girl\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"government\", \"government\", \"government\", \"government\", \"government\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"guess\", \"guess\", \"guess\", \"guidance\", \"guideline\", \"hand\", \"handle\", \"happen\", \"happen\", \"happen\", \"happy\", \"happy\", \"happy\", \"head\", \"health\", \"health\", \"health\", \"health\", \"health\", \"help\", \"help\", \"help\", \"high\", \"high\", \"high\", \"high\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"hope\", \"hope\", \"hope\", \"hope\", \"hot\", \"house\", \"idea\", \"idea\", \"ill\", \"immunity\", \"increase\", \"increase\", \"individual\", \"infection\", \"infection\", \"infection\", \"infection\", \"inflation\", \"instead\", \"interesting\", \"interview\", \"issue\", \"issue\", \"issue\", \"issue\", \"job\", \"job\", \"job\", \"joke\", \"keep\", \"kid\", \"kid\", \"kid\", \"kill\", \"kill\", \"kill\", \"kill\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"later\", \"lead\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"level\", \"level\", \"level\", \"line\", \"listen\", \"little\", \"little\", \"little\", \"little\", \"little\", \"lockdown\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"loss\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"low\", \"low\", \"lung\", \"m\", \"m\", \"m\", \"m\", \"major\", \"major\", \"man\", \"manage\", \"mandate\", \"mandate\", \"market\", \"mask\", \"mask\", \"mask\", \"mask\", \"maybe\", \"medium\", \"medium\", \"medium\", \"meeting\", \"mention\", \"message\", \"mild\", \"mild\", \"misinformation\", \"mom\", \"money\", \"money\", \"month\", \"month\", \"month\", \"month\", \"month\", \"morning\", \"movie\", \"nearly\", \"need\", \"need\", \"need\", \"need\", \"need\", \"negative\", \"new\", \"new\", \"new\", \"new\", \"new\", \"news\", \"news\", \"news\", \"news\", \"night\", \"number\", \"number\", \"number\", \"number\", \"official\", \"official\", \"official\", \"official\", \"online\", \"origin\", \"outbreak\", \"outbreak\", \"outbreak\", \"pain\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"pandemic\", \"patient\", \"patient\", \"patient\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"period\", \"play\", \"policy\", \"policy\", \"positive\", \"positive\", \"power\", \"pretty\", \"pretty\", \"pretty\", \"previous\", \"price\", \"probably\", \"probably\", \"probably\", \"protect\", \"protect\", \"protect\", \"protection\", \"protection\", \"protocol\", \"public\", \"public\", \"public\", \"publish\", \"question\", \"question\", \"question\", \"raise\", \"rapid\", \"rate\", \"rate\", \"real\", \"recent\", \"recent\", \"recent\", \"recently\", \"recently\", \"recommend\", \"recommend\", \"recommendation\", \"reduce\", \"refuse\", \"relate\", \"release\", \"release\", \"remember\", \"remove\", \"report\", \"report\", \"requirement\", \"requirement\", \"research\", \"research\", \"research\", \"research\", \"researcher\", \"restriction\", \"restriction\", \"restriction\", \"restriction\", \"restriction\", \"reveal\", \"right\", \"right\", \"right\", \"rise\", \"rise\", \"rise\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"rule\", \"rule\", \"safety\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"school\", \"school\", \"school\", \"school\", \"school\", \"science\", \"science\", \"science\", \"science\", \"scientist\", \"season\", \"send\", \"send\", \"seriously\", \"severe\", \"severe\", \"shit\", \"shit\", \"shoot\", \"short\", \"shot\", \"shot\", \"shot\", \"shot\", \"show\", \"show\", \"show\", \"show\", \"show\", \"shut\", \"sick\", \"sick\", \"sick\", \"sick\", \"sit\", \"situation\", \"small\", \"soon\", \"soon\", \"sorry\", \"source\", \"staff\", \"staff\", \"start\", \"start\", \"start\", \"start\", \"start\", \"start\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"statement\", \"stop\", \"stop\", \"stop\", \"stop\", \"stop\", \"story\", \"story\", \"story\", \"strain\", \"stream\", \"student\", \"student\", \"study\", \"study\", \"study\", \"study\", \"stuff\", \"stuff\", \"suck\", \"suggest\", \"summer\", \"suppose\", \"sure\", \"sure\", \"surge\", \"surge\", \"surge\", \"surge\", \"survive\", \"symptom\", \"symptom\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"taste\", \"taste\", \"taste\", \"teacher\", \"teacher\", \"teacher\", \"team\", \"team\", \"team\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"test\", \"test\", \"tested_positive\", \"tested_positive\", \"tested_positive\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thread\", \"thread\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tired\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"tomorrow\", \"tonight\", \"tonight\", \"total\", \"travel\", \"travel\", \"travel\", \"travel\", \"trip\", \"true\", \"trump\", \"trump\", \"trust\", \"turn\", \"tv\", \"tweet\", \"twice\", \"twitter\", \"understand\", \"understand\", \"update\", \"vacation\", \"vaccinate\", \"vaccinate\", \"vaccinate\", \"vaccinate\", \"vaccinate\", \"vaccination\", \"vaccination\", \"vaccination\", \"vaccination\", \"vaccination\", \"vaccination\", \"vaccine\", \"vaccine\", \"vaccine\", \"vaccine\", \"vaccine\", \"variant\", \"variant\", \"variant\", \"ve\", \"ve\", \"ve\", \"virus\", \"virus\", \"virus\", \"virus\", \"virus\", \"virus\", \"visit\", \"wake\", \"walk\", \"walk\", \"want\", \"want\", \"want\", \"want\", \"war\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"water\", \"way\", \"way\", \"way\", \"way\", \"we_re\", \"wear\", \"wear\", \"wear\", \"week\", \"week\", \"week\", \"week\", \"week\", \"week\", \"weekly\", \"well\", \"well\", \"well\", \"well\", \"win\", \"wish\", \"wonder\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"worldwide\", \"write\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"you_re\", \"you_re\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 2, 3, 6, 4, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el153081405335534914084496485383\", ldavis_el153081405335534914084496485383_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el153081405335534914084496485383\", ldavis_el153081405335534914084496485383_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el153081405335534914084496485383\", ldavis_el153081405335534914084496485383_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4     -0.205596  0.006546       1        1  20.933106\n",
       "1     -0.047577  0.068934       2        1  20.210591\n",
       "2      0.080043  0.158061       3        1  17.375923\n",
       "5     -0.204396 -0.088288       4        1  15.341729\n",
       "3      0.185486 -0.278075       5        1  13.364918\n",
       "0      0.192040  0.132822       6        1  12.773733, topic_info=            Term          Freq         Total Category  logprob  loglift\n",
       "168      vaccine  14573.000000  14573.000000  Default  30.0000  30.0000\n",
       "85          case   8755.000000   8755.000000  Default  29.0000  29.0000\n",
       "130         test   9409.000000   9409.000000  Default  28.0000  28.0000\n",
       "180          new  10398.000000  10398.000000  Default  27.0000  27.0000\n",
       "74           get  16870.000000  16870.000000  Default  26.0000  26.0000\n",
       "...          ...           ...           ...      ...      ...      ...\n",
       "492     pandemic   1120.506902   6452.213308   Topic6  -5.1292   0.3071\n",
       "30          year   1161.936855   9287.008981   Topic6  -5.0929  -0.0207\n",
       "380   government    899.318190   2874.970596   Topic6  -5.3491   0.8956\n",
       "684        cause    822.671469   2773.975092   Topic6  -5.4382   0.8423\n",
       "1129        call    764.818332   1639.965988   Topic6  -5.5111   1.2950\n",
       "\n",
       "[418 rows x 6 columns], token_table=      Topic      Freq    Term\n",
       "term                         \n",
       "4123      6  0.996792  accept\n",
       "747       3  0.997449  active\n",
       "1576      5  0.972836     add\n",
       "1576      6  0.025981     add\n",
       "2330      2  0.998892   admit\n",
       "...     ...       ...     ...\n",
       "30        4  0.063314    year\n",
       "30        5  0.106062    year\n",
       "30        6  0.125121    year\n",
       "10        2  0.998330  you_re\n",
       "10        3  0.001420  you_re\n",
       "\n",
       "[794 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 2, 3, 6, 4, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a909041",
   "metadata": {},
   "source": [
    "#### Interpretation of results per topic\n",
    "1. Covid health (symptom, feel, bad, long, sick)\n",
    "2. Covid politics (government, public, official, lockdown, people)\n",
    "3. Covid measures (mask, wear, infection, high, rate, variant)\n",
    "4. Unninterpretable\n",
    "5. Covid vaccine (vaccine, child, booster, risk, dose, study)\n",
    "6. Covid results (test, case, positive, death, new, day, report, daily, rise)\n",
    "7. Covid conspiracy (virus, tell, try, lie, wonder, policy, fake)\n",
    "8. Unninterpretable\n",
    "9. Covid vaccine (vaccine, update, kid, young, vaccination, booost, pfizer)\n",
    "10. Unninterpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03280bb7",
   "metadata": {},
   "source": [
    "## Save the topics and interpretation in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8897603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12de2915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15308/2440210496.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
      "/tmp/ipykernel_15308/2440210496.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=df):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    return(sent_topics_df)\n",
    "\n",
    "df_dominant_topic = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=df[\"lemmatized_text\"])\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_dominant_topic.reset_index()\n",
    "df_dominant_topic.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21a8c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "final_df = pd.concat([df_copy.reset_index(drop=True), df_dominant_topic.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322f37d",
   "metadata": {},
   "source": [
    "## Save final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a23c7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_parquet(os.getcwd()+'/data_storage/data/twitter_data.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d06843",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc413aa",
   "metadata": {},
   "source": [
    "#### Elbow method to decide K number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05ea1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute u_mass coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdccc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=2, limit=20, step=4)\n",
    "\n",
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "limit=20; start=2; step=4;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75224ebc",
   "metadata": {},
   "source": [
    "#### Tune parameters alpha and eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db44f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of topics based on elbow method result\n",
    "k = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea474b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_lda(k):\n",
    "    results = []\n",
    "\n",
    "    # Alpha parameter\n",
    "    alpha = list(np.arange(0.01, 1, 0.3))\n",
    "    alpha.append('symmetric')\n",
    "    alpha.append('asymmetric')\n",
    "\n",
    "    # Beta parameter\n",
    "    beta = list(np.arange(0.01, 1, 0.3))\n",
    "    beta.append('symmetric')\n",
    "    \n",
    "    for a in alpha:\n",
    "        for b in beta:\n",
    "            lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                    id2word=id2word,\n",
    "                                    num_topics=k, \n",
    "                                    random_state=100,\n",
    "                                    chunksize=100,\n",
    "                                    passes=2,\n",
    "                                    per_word_topics=True,\n",
    "                                    alpha=a,\n",
    "                                    eta=b\n",
    "                                    )\n",
    "\n",
    "            coherence_model_lda = CoherenceModel(model=lda_model,\n",
    "                                                corpus=corpus,\n",
    "                                                texts=texts,\n",
    "                                                dictionary=id2word,\n",
    "                                                coherence='u_mass') \n",
    "\n",
    "            # get coherence value\n",
    "            coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "            # save results\n",
    "            results_dict = {'alpha': a,\n",
    "                            'beta': b,\n",
    "                            'K': k,\n",
    "                            'Coherence score': coherence_lda}\n",
    "            \n",
    "            results.append(results_dict)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10f2cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilgoncalo/miniconda3/envs/dataalliance/lib/python3.9/site-packages/astroid/node_classes.py:94: DeprecationWarning: The 'astroid.node_classes' module is deprecated and will be replaced by 'astroid.nodes' in astroid 3.0.0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "auto-tuning alpha not implemented in LdaMulticore; use plain LdaModel.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=0'>1</a>\u001b[0m optimization_results \u001b[39m=\u001b[39m optimize_lda(\u001b[39m6\u001b[39;49m)\n",
      "\u001b[1;32m/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb Cell 19\u001b[0m in \u001b[0;36moptimize_lda\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m eta:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m per_word_topics:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=10'>11</a>\u001b[0m         lda_model \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mLdaMulticore(corpus\u001b[39m=\u001b[39;49mcorpus,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=11'>12</a>\u001b[0m                                 id2word\u001b[39m=\u001b[39;49mid2word,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=12'>13</a>\u001b[0m                                 num_topics\u001b[39m=\u001b[39;49mk, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=13'>14</a>\u001b[0m                                 random_state\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=14'>15</a>\u001b[0m                                 chunksize\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=15'>16</a>\u001b[0m                                 passes\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=16'>17</a>\u001b[0m                                 per_word_topics\u001b[39m=\u001b[39;49mp,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=17'>18</a>\u001b[0m                                 alpha\u001b[39m=\u001b[39;49ma,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=18'>19</a>\u001b[0m                                 eta\u001b[39m=\u001b[39;49me\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=19'>20</a>\u001b[0m                                 )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=21'>22</a>\u001b[0m         coherence_model_lda \u001b[39m=\u001b[39m CoherenceModel(model\u001b[39m=\u001b[39mlda_model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=22'>23</a>\u001b[0m                                             corpus\u001b[39m=\u001b[39mcorpus,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=23'>24</a>\u001b[0m                                             texts\u001b[39m=\u001b[39mtexts,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=24'>25</a>\u001b[0m                                             dictionary\u001b[39m=\u001b[39mid2word,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=25'>26</a>\u001b[0m                                             coherence\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mu_mass\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/devilgoncalo/Westbrook/Documents/srh_masters/case_studies_1/dataalliance/module_dataalliance/twitter_lda.ipynb#X24sanVweXRleHQ%3D?line=27'>28</a>\u001b[0m         \u001b[39m# get coherence value\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dataalliance/lib/python3.9/site-packages/gensim/models/ldamulticore.py:184\u001b[0m, in \u001b[0;36mLdaMulticore.__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch \u001b[39m=\u001b[39m batch\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(alpha, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m alpha \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mauto-tuning alpha not implemented in LdaMulticore; use plain LdaModel.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    186\u001b[0m \u001b[39msuper\u001b[39m(LdaMulticore, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    187\u001b[0m     corpus\u001b[39m=\u001b[39mcorpus, num_topics\u001b[39m=\u001b[39mnum_topics,\n\u001b[1;32m    188\u001b[0m     id2word\u001b[39m=\u001b[39mid2word, chunksize\u001b[39m=\u001b[39mchunksize, passes\u001b[39m=\u001b[39mpasses, alpha\u001b[39m=\u001b[39malpha, eta\u001b[39m=\u001b[39meta,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m     minimum_phi_value\u001b[39m=\u001b[39mminimum_phi_value, per_word_topics\u001b[39m=\u001b[39mper_word_topics, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m    192\u001b[0m )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: auto-tuning alpha not implemented in LdaMulticore; use plain LdaModel."
     ]
    }
   ],
   "source": [
    "optimization_results = optimize_lda(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820747ae",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Save model to disk.\n",
    "temp_file = datapath(\"model\")\n",
    "lda.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b851f95",
   "metadata": {},
   "source": [
    "#### More hyperparameter tunning (don't have the machine for it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa01439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=2,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model,\n",
    "                                        corpus=corpus,\n",
    "                                        texts=texts,\n",
    "                                        dictionary=id2word,\n",
    "                                        coherence='u_mass')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa03f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), corpus]\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through alpha values\n",
    "        for a in alpha:\n",
    "            # iterare through beta values\n",
    "            for b in beta:\n",
    "                # get the coherence score for the given parameters\n",
    "                cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                k=k, a=a, b=b)\n",
    "                # Save the model results\n",
    "                model_results['Validation_Set'].append(corpus_title[i])\n",
    "                model_results['Topics'].append(k)\n",
    "                model_results['Alpha'].append(a)\n",
    "                model_results['Beta'].append(b)\n",
    "                model_results['Coherence'].append(cv)\n",
    "                \n",
    "                pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv(os.getcwd()+'/models/lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc20ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read results\n",
    "df_results = pd.read_csv(os.getcwd()+'/models/lda_tuning_results.csv')\n",
    "\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "custom_cell_magics": "kql"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dataalliance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d868e12043a3b0a2d77b05f5f9b9481227f401f45b03b0f283d3bf8f7ccf94e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
